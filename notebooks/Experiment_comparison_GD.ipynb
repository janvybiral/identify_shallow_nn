{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from copy import deepcopy\n",
    "from identification_shallownn.SNN import SNN, generate_random_SNN\n",
    "from identification_shallownn.identifying_SNN import identify_weights, gradient_descent_A\n",
    "from identification_shallownn.matrix_manip import normalize_col\n",
    "from identification_shallownn.modules.experiment import Experiment \n",
    "import pickle\n",
    "import pathlib\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_once(d,m,n_rep,eps_A,number_evaluation_samples, number_hessians, repetition):\n",
    "    metrics = pd.Series(dtype='float')\n",
    "    \n",
    "    #Create a random network which remains over repetition\n",
    "    net = generate_random_SNN(d=d,m=m,eps_A=eps_A, seed=repetition)\n",
    "\n",
    "    #Creating a test set for evaluation\n",
    "    np.random.seed(repetition)\n",
    "    X_test = np.random.normal(size=(number_evaluation_samples, net.d))\n",
    "    X_test = normalize_col(X_test.T).T\n",
    "    rad = np.random.uniform(size=number_evaluation_samples)**(1/d)\n",
    "    X_test = (X_test.T*rad).T\n",
    "    Y_test = net.eval(X_test)\n",
    "    \n",
    "    X = np.random.normal(size=(number_hessians, net.m))\n",
    "    X = normalize_col(X.T).T\n",
    "    A_FSV = identify_weights(net, X, n_rep)\n",
    "    metrics[\"error_A_FVD\"] = np.linalg.norm(net.A - A_FSV)\n",
    "    #Creating new network with Anew as weights\n",
    "    net_approximation_FVD = SNN(A=A_FSV, b=net.b, s1=net.s1,s2=net.s2, act=net.g, dact=net.dg)\n",
    "    metrics[\"MSE_net_FVD\"] = np.mean((net.eval(X_test) - net_approximation_FVD.eval(X_test))**2)\n",
    "    metrics[\"Linf_net_FVD\"] = np.max(np.abs(net.eval(X_test) - net_approximation_FVD.eval(X_test)))\n",
    "\n",
    "    #Samples used for gradient descent are number_hessians*the number of samples used for finite differences\n",
    "    N_samples_gd = int(number_hessians * (d*(d+1)/2 + 1))\n",
    "    X_train = np.random.normal(size=(N_samples_gd, m))\n",
    "    X_train = normalize_col(X.T).T\n",
    "    Y_train = net.eval(X_train)\n",
    "    \n",
    "    net_approximation_gd = SNN(A=np.zeros(shape=(d,m)), b=net.b, s1=net.s1,s2=net.s2, act=net.g, dact=net.dg)\n",
    "    \n",
    "    losses = gradient_descent_A(X_train, Y_train, net_approximation_gd, 1000, 0.1)\n",
    "    metrics['losses_gd'] = losses\n",
    "    metrics[\"error_A_gd\"] = np.linalg.norm(net.A-net_approximation_gd.A)\n",
    "\n",
    "    metrics[\"MSE_net_gd\"] = np.mean((net.eval(X_test) - net_approximation_gd.eval(X_test))**2)\n",
    "    metrics[\"Linf_net_gd\"] = np.max(np.abs(net.eval(X_test) - net_approximation_gd.eval(X_test)))\n",
    "    \n",
    "    return metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = 'comparison_to_gd'\n",
    "\n",
    "host_config = {\n",
    "    'output_dir': '/media/data/sherlock/results'\n",
    "}\n",
    "\n",
    "fixed_params = {\n",
    "    'd':20,\n",
    "    'm':20,\n",
    "    'n_rep':180,\n",
    "    'eps_A':1,\n",
    "    'number_evaluation_samples':10**5\n",
    "}\n",
    "\n",
    "varying_params = {\n",
    "    'number_hessians': np.arange(start=1, stop=32,dtype=\"int\"),\n",
    "    'repetition':np.arange(start=0, stop=10, dtype=\"int\")\n",
    "}\n",
    "\n",
    "experiment = Experiment(\n",
    "    run_once = run_once,\n",
    "    fixed_params = fixed_params,\n",
    "    varying_params = varying_params,\n",
    "    host_config = host_config,\n",
    "    handle = handle,\n",
    "    use_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>d</th>\n",
       "      <th>m</th>\n",
       "      <th>n_rep</th>\n",
       "      <th>eps_A</th>\n",
       "      <th>number_evaluation_samples</th>\n",
       "      <th>number_hessians</th>\n",
       "      <th>repetition</th>\n",
       "      <th>error_A_FVD</th>\n",
       "      <th>MSE_net_FVD</th>\n",
       "      <th>Linf_net_FVD</th>\n",
       "      <th>losses_gd</th>\n",
       "      <th>error_A_gd</th>\n",
       "      <th>MSE_net_gd</th>\n",
       "      <th>Linf_net_gd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.497664</td>\n",
       "      <td>4.042486e-02</td>\n",
       "      <td>0.741095</td>\n",
       "      <td>[0.06248046911288859, 0.04149466503688739, 0.0...</td>\n",
       "      <td>4.462948</td>\n",
       "      <td>0.037661</td>\n",
       "      <td>0.721143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.480960</td>\n",
       "      <td>4.018760e-02</td>\n",
       "      <td>0.803699</td>\n",
       "      <td>[0.0035582588795612623, 0.002363187118807135, ...</td>\n",
       "      <td>4.471796</td>\n",
       "      <td>0.040450</td>\n",
       "      <td>0.801174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4.456673</td>\n",
       "      <td>4.303922e-02</td>\n",
       "      <td>0.739573</td>\n",
       "      <td>[0.0008208665609346762, 0.0005517116142599006,...</td>\n",
       "      <td>4.472195</td>\n",
       "      <td>0.043083</td>\n",
       "      <td>0.742945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.462657</td>\n",
       "      <td>3.981723e-02</td>\n",
       "      <td>0.711758</td>\n",
       "      <td>[0.01404902534968421, 0.009296597228174799, 0....</td>\n",
       "      <td>4.470086</td>\n",
       "      <td>0.039359</td>\n",
       "      <td>0.723995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4.426523</td>\n",
       "      <td>3.534983e-02</td>\n",
       "      <td>0.753536</td>\n",
       "      <td>[0.020695492228828483, 0.01353154932302645, 0....</td>\n",
       "      <td>4.469635</td>\n",
       "      <td>0.035042</td>\n",
       "      <td>0.747953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>100000</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>2.382692e-09</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>[0.048761442988098765, 0.04742283523617502, 0....</td>\n",
       "      <td>4.355248</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.103085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>100000</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>0.001351</td>\n",
       "      <td>5.163331e-09</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>[0.04456171333973311, 0.04328511237115131, 0.0...</td>\n",
       "      <td>4.368060</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.089380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>100000</td>\n",
       "      <td>31</td>\n",
       "      <td>7</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>1.145970e-09</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>[0.05706278143721869, 0.05506381016984862, 0.0...</td>\n",
       "      <td>4.348644</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.086040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>100000</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>0.001215</td>\n",
       "      <td>8.856076e-10</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>[0.03341564238700435, 0.03256599417589382, 0.0...</td>\n",
       "      <td>4.364455</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.109501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>100000</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>3.586030e-09</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>[0.06932129754768243, 0.0671188796089008, 0.06...</td>\n",
       "      <td>4.326221</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.115998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>310 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      d   m  n_rep  eps_A  number_evaluation_samples  number_hessians  \\\n",
       "0    20  20    200      1                     100000                1   \n",
       "1    20  20    200      1                     100000                1   \n",
       "2    20  20    200      1                     100000                1   \n",
       "3    20  20    200      1                     100000                1   \n",
       "4    20  20    200      1                     100000                1   \n",
       "..   ..  ..    ...    ...                        ...              ...   \n",
       "305  20  20    200      1                     100000               31   \n",
       "306  20  20    200      1                     100000               31   \n",
       "307  20  20    200      1                     100000               31   \n",
       "308  20  20    200      1                     100000               31   \n",
       "309  20  20    200      1                     100000               31   \n",
       "\n",
       "     repetition  error_A_FVD   MSE_net_FVD  Linf_net_FVD  \\\n",
       "0             0     4.497664  4.042486e-02      0.741095   \n",
       "1             1     4.480960  4.018760e-02      0.803699   \n",
       "2             2     4.456673  4.303922e-02      0.739573   \n",
       "3             3     4.462657  3.981723e-02      0.711758   \n",
       "4             4     4.426523  3.534983e-02      0.753536   \n",
       "..          ...          ...           ...           ...   \n",
       "305           5     0.001089  2.382692e-09      0.000184   \n",
       "306           6     0.001351  5.163331e-09      0.000264   \n",
       "307           7     0.001193  1.145970e-09      0.000123   \n",
       "308           8     0.001215  8.856076e-10      0.000111   \n",
       "309           9     0.001133  3.586030e-09      0.000227   \n",
       "\n",
       "                                             losses_gd  error_A_gd  \\\n",
       "0    [0.06248046911288859, 0.04149466503688739, 0.0...    4.462948   \n",
       "1    [0.0035582588795612623, 0.002363187118807135, ...    4.471796   \n",
       "2    [0.0008208665609346762, 0.0005517116142599006,...    4.472195   \n",
       "3    [0.01404902534968421, 0.009296597228174799, 0....    4.470086   \n",
       "4    [0.020695492228828483, 0.01353154932302645, 0....    4.469635   \n",
       "..                                                 ...         ...   \n",
       "305  [0.048761442988098765, 0.04742283523617502, 0....    4.355248   \n",
       "306  [0.04456171333973311, 0.04328511237115131, 0.0...    4.368060   \n",
       "307  [0.05706278143721869, 0.05506381016984862, 0.0...    4.348644   \n",
       "308  [0.03341564238700435, 0.03256599417589382, 0.0...    4.364455   \n",
       "309  [0.06932129754768243, 0.0671188796089008, 0.06...    4.326221   \n",
       "\n",
       "     MSE_net_gd  Linf_net_gd  \n",
       "0      0.037661     0.721143  \n",
       "1      0.040450     0.801174  \n",
       "2      0.043083     0.742945  \n",
       "3      0.039359     0.723995  \n",
       "4      0.035042     0.747953  \n",
       "..          ...          ...  \n",
       "305    0.000752     0.103085  \n",
       "306    0.000451     0.089380  \n",
       "307    0.000516     0.086040  \n",
       "308    0.000560     0.109501  \n",
       "309    0.000659     0.115998  \n",
       "\n",
       "[310 rows x 14 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snnident",
   "language": "python",
   "name": "snnident"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
